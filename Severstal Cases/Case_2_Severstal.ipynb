{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [ 
    "##### Для автоматической сортировки одного из ключевых продуктов предприятия по двум категориям\n",
    "##### Вам необходимо разработать модель, которая позволит предсказывать категории этого продукта по показаниям датчиков. Вы договорились, что показателем, характеризующим качество Вашей модели, будет AUC. Все необходимые данные лежат по ссылке:\n",
    "##### https://www.dropbox.com/s/u9mby8wlb9f8xyr/case2.7z?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Datasets/SeverStal/xtrain.csv', sep = ',')\n",
    "X_test = pd.read_csv('C:/Datasets/SeverStal/xtest.csv', sep = ',')\n",
    "y_X_train = pd.read_csv('C:/Datasets/SeverStal/ytrain.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим в категориальные переменные те, у которых небольшое количество уникальных значений\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].nunique() < 30:\n",
    "        X_train[i] = X_train[i].astype('str', copy = False)\n",
    "    if X_test[i].nunique() < 30:\n",
    "        X_test[i] = X_test[i].astype('str', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем объединение редких категорий на обучающей и тестовой выборке\n",
    "X_train['2'].replace(['8.0','7.0','9.0'], '13.0', inplace = True)\n",
    "X_train['3'].replace(['3.0','4.0','5.0', '6.0'], '12.0', inplace = True)\n",
    "X_train['5'].replace(['3.0','4.0'], '0.0', inplace = True)\n",
    "X_train['7'].replace(['17.0','18.0','19.0','20.0'], '24.0', inplace = True)\n",
    "X_train['9'].replace(['1.0','2.0', '3.0', '4.0'], '8.0', inplace = True)\n",
    "X_train['15'].replace(['8.0','9.0','10.0', '11.0', '12.0'], '17.0', inplace = True)\n",
    "X_train['17'].replace(['7.0','8.0','9.0', '10.0', '11.0'], '17.0', inplace = True)\n",
    "X_train['18'].replace(['8.0','9.0','10.0','11.0', '12.0'], '3.0', inplace = True)\n",
    "X_train['21'].replace(['17.0','19.0','16.0','15.0', '14.0', '13.0', '12.0', '11.0', '10.0'], '3.0', inplace = True)\n",
    "X_train['22'].replace(['11.0','12.0', '10.0', '0.0'], '4.0', inplace = True)\n",
    "X_train['24'].replace(['12.0','13.0','14.0', '15.0', '11.0', '0.0'], '5.0', inplace = True)\n",
    "X_train['26'].replace(['3.0','4.0', '5.0', '6.0', '20.0', '7.0'], '14.0', inplace = True)\n",
    "X_train['27'].replace(['2.0','3.0', '22.0', '23.0','4.0','21.0', '5.0', '20.0', '6.0'], '13.0', inplace = True)\n",
    "X_train['29'].replace(['9.0','10.0', '11.0', '12.0', '8.0'], '3.0', inplace = True)\n",
    "X_train['30'].replace(['4.0','5.0'], '0.0', inplace = True)\n",
    "X_train['31'].replace('0.0', '4.0', inplace = True)\n",
    "X_train['32'].replace('9.0', '4.0', inplace = True)\n",
    "X_train['36'].replace(['10.0', '11.0', '12.0', '13.0', '9.0'], '3.0', inplace = True)\n",
    "X_train['45'].replace(['4.0','6.0', '5.0', '7.0'], '11.0', inplace = True)\n",
    "X_train['48'].replace(['10.0', '11.0', '12.0', '13.0'], '4.0', inplace = True)\n",
    "X_train['51'].replace(['4.0','5.0','6.0','7.0','22.0','23.0', '21.0', '8.0'], '15.0', inplace = True)\n",
    "\n",
    "X_test['2'].replace(['8.0','7.0','9.0'], '13.0', inplace = True)\n",
    "X_test['3'].replace(['3.0','4.0','5.0', '6.0'], '12.0', inplace = True)\n",
    "X_test['5'].replace(['3.0','4.0'], '0.0', inplace = True)\n",
    "X_test['7'].replace(['17.0','18.0','19.0','20.0'], '24.0', inplace = True)\n",
    "X_test['9'].replace(['1.0','2.0', '3.0', '4.0'], '8.0', inplace = True)\n",
    "X_test['15'].replace(['8.0','9.0','10.0', '11.0', '12.0'], '17.0', inplace = True)\n",
    "X_test['17'].replace(['7.0','8.0','9.0', '10.0', '11.0'], '17.0', inplace = True)\n",
    "X_test['18'].replace(['8.0','9.0','10.0','11.0', '12.0'], '3.0', inplace = True)\n",
    "X_test['21'].replace(['17.0','19.0','16.0','15.0', '14.0', '13.0', '12.0', '11.0', '10.0'], '3.0', inplace = True)\n",
    "X_test['22'].replace(['11.0','12.0', '10.0', '0.0'], '4.0', inplace = True)\n",
    "X_test['24'].replace(['12.0','13.0','14.0', '15.0', '11.0', '0.0'], '5.0', inplace = True)\n",
    "X_test['26'].replace(['3.0','4.0', '5.0', '6.0', '20.0', '7.0'], '14.0', inplace = True)\n",
    "X_test['27'].replace(['2.0','3.0', '22.0', '23.0','4.0','21.0', '5.0', '20.0', '6.0'], '13.0', inplace = True)\n",
    "X_test['29'].replace(['9.0','10.0', '11.0', '12.0', '8.0'], '3.0', inplace = True)\n",
    "X_test['30'].replace(['4.0','5.0'], '0.0', inplace = True)\n",
    "X_test['31'].replace('0.0', '4.0', inplace = True)\n",
    "X_test['32'].replace('9.0', '4.0', inplace = True)\n",
    "X_test['36'].replace(['10.0', '11.0', '12.0', '13.0', '9.0'], '3.0', inplace = True)\n",
    "X_test['45'].replace(['4.0','6.0', '5.0', '7.0'], '11.0', inplace = True)\n",
    "X_test['48'].replace(['10.0', '11.0', '12.0', '13.0'], '4.0', inplace = True)\n",
    "X_test['51'].replace(['4.0','5.0','6.0','7.0','22.0','23.0', '21.0', '8.0'], '15.0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем разбиение нашей выборки, для которой есть реальные прогнозы на обучение и тест\n",
    "df1 = pd.concat([X_train, y_X_train], axis=1)\n",
    "\n",
    "train = df1.sample(frac = 0.7, random_state = 200)\n",
    "test = df1.drop(train.index)\n",
    "\n",
    "y_train = train['x']\n",
    "train.drop('x', axis=1, inplace = True)\n",
    "\n",
    "y_test = test['x']\n",
    "test.drop('x', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем импутацию пропусков медианой. Для метода out-of-range результат был тот же\n",
    "for i in X_train.columns:\n",
    "    train[i].fillna(train[i].median(), inplace = True)\n",
    "    test[i].fillna(train[i].median(), inplace = True)\n",
    "    X_test[i].fillna(train[i].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим некоторые дополнительные признаки\n",
    "for i in [k for k in train.columns if train[k].dtype.name == 'float64']:\n",
    "    train[i + 'square'] = train[i]**2\n",
    "    test[i + 'square'] = test[i]**2\n",
    "    X_test[i + 'square'] = X_test[i]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проделаем кодирование относительными частотами для категориальных предикторов\n",
    "for i in [k for k in train.columns if train[k].dtype.name == 'object']:\n",
    "    freq_encoding = train[i].value_counts() / len(train[i])\n",
    "    train[i + '+' + 'freq'] = train[i].map(freq_encoding)\n",
    "    test[i + '+' + 'freq'] = test[i].map(freq_encoding)\n",
    "    X_test[i + '+' + 'freq'] = X_test[i].map(freq_encoding)\n",
    "    \n",
    "# проделаем кодирование абсолютными частотами для категориальных предикторов\n",
    "for i in [k for k in train.columns if train[k].dtype.name == 'object']:\n",
    "    abs_freq_encoding = train[i].value_counts()\n",
    "    train[i + '+' + 'abs_freq'] = train[i].map(abs_freq_encoding)\n",
    "    test[i + '+' + 'abs_freq'] = test[i].map(abs_freq_encoding)\n",
    "    X_test[i + '+' + 'abs_freq'] = X_test[i].map(abs_freq_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем dummy-кодирование категориальных переменных\n",
    "train_dummy = pd.get_dummies(train)\n",
    "test_dummy = pd.get_dummies(test)\n",
    "X_test_dummy = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dummy.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor: 1 Lambda: 0.336194\n",
      "predictor: 4 Lambda: 0.576818\n",
      "predictor: 8 Lambda: 0.905872\n",
      "predictor: 11 Lambda: 0.360852\n",
      "predictor: 12 Lambda: 0.525670\n",
      "predictor: 13 Lambda: 0.439976\n",
      "predictor: 14 Lambda: 0.840189\n",
      "predictor: 16 Lambda: 0.644224\n",
      "predictor: 19 Lambda: 0.383165\n",
      "predictor: 20 Lambda: 0.391915\n",
      "predictor: 25 Lambda: 0.321578\n",
      "predictor: 28 Lambda: 1.032010\n",
      "predictor: 33 Lambda: 0.604927\n",
      "predictor: 34 Lambda: 0.976551\n",
      "predictor: 35 Lambda: 0.668472\n",
      "predictor: 37 Lambda: -0.128746\n",
      "predictor: 38 Lambda: 0.581504\n",
      "predictor: 39 Lambda: 0.377621\n",
      "predictor: 40 Lambda: 0.492244\n",
      "predictor: 41 Lambda: 0.374072\n",
      "predictor: 42 Lambda: 0.382740\n",
      "predictor: 43 Lambda: 1.022459\n",
      "predictor: 46 Lambda: 0.426376\n",
      "predictor: 49 Lambda: 1.012837\n",
      "predictor: 52 Lambda: 0.466242\n",
      "predictor: 53 Lambda: 0.377361\n",
      "predictor: 54 Lambda: 0.367526\n",
      "predictor: 55 Lambda: 0.541921\n",
      "predictor: 56 Lambda: 0.992956\n",
      "predictor: 57 Lambda: 1.026402\n",
      "predictor: 58 Lambda: 0.924447\n",
      "predictor: 1square Lambda: 0.168097\n",
      "predictor: 4square Lambda: 0.288409\n",
      "predictor: 8square Lambda: 0.452936\n",
      "predictor: 11square Lambda: 0.180426\n",
      "predictor: 12square Lambda: 0.262835\n",
      "predictor: 13square Lambda: 0.219988\n",
      "predictor: 14square Lambda: 0.420094\n",
      "predictor: 16square Lambda: 0.322112\n",
      "predictor: 19square Lambda: 0.191583\n",
      "predictor: 20square Lambda: 0.195958\n",
      "predictor: 25square Lambda: 0.160789\n",
      "predictor: 28square Lambda: 0.516005\n",
      "predictor: 33square Lambda: 0.302464\n",
      "predictor: 34square Lambda: 0.488275\n",
      "predictor: 35square Lambda: 0.334236\n",
      "predictor: 37square Lambda: -0.064373\n",
      "predictor: 38square Lambda: 0.290752\n",
      "predictor: 39square Lambda: 0.188810\n",
      "predictor: 40square Lambda: 0.246122\n",
      "predictor: 41square Lambda: 0.187036\n",
      "predictor: 42square Lambda: 0.191370\n",
      "predictor: 43square Lambda: 0.511230\n",
      "predictor: 46square Lambda: 0.213188\n",
      "predictor: 49square Lambda: 0.506418\n",
      "predictor: 52square Lambda: 0.233121\n",
      "predictor: 53square Lambda: 0.188681\n",
      "predictor: 54square Lambda: 0.183763\n",
      "predictor: 55square Lambda: 0.270960\n",
      "predictor: 56square Lambda: 0.496478\n",
      "predictor: 57square Lambda: 0.513201\n",
      "predictor: 58square Lambda: 0.462224\n",
      "predictor: 2+freq Lambda: 1.476960\n",
      "predictor: 3+freq Lambda: 1.303700\n",
      "predictor: 5+freq Lambda: 1.360663\n",
      "predictor: 6+freq Lambda: 2.129595\n",
      "predictor: 7+freq Lambda: 1.625136\n",
      "predictor: 9+freq Lambda: 1.370512\n",
      "predictor: 10+freq Lambda: 1.530380\n",
      "predictor: 15+freq Lambda: 1.418165\n",
      "predictor: 17+freq Lambda: 1.339855\n",
      "predictor: 18+freq Lambda: 1.287568\n",
      "predictor: 21+freq Lambda: 1.405187\n",
      "predictor: 22+freq Lambda: 1.314721\n",
      "predictor: 23+freq Lambda: 0.967400\n",
      "predictor: 24+freq Lambda: 1.298801\n",
      "predictor: 26+freq Lambda: 1.338248\n",
      "predictor: 27+freq Lambda: 1.682467\n",
      "predictor: 29+freq Lambda: 1.392451\n",
      "predictor: 30+freq Lambda: 1.280578\n",
      "predictor: 31+freq Lambda: 1.222675\n",
      "predictor: 32+freq Lambda: 1.286915\n",
      "predictor: 36+freq Lambda: 1.282765\n",
      "predictor: 44+freq Lambda: 1.660219\n",
      "predictor: 45+freq Lambda: 1.420735\n",
      "predictor: 47+freq Lambda: 1.972705\n",
      "predictor: 48+freq Lambda: 1.322144\n",
      "predictor: 50+freq Lambda: 1.375670\n",
      "predictor: 51+freq Lambda: 1.584609\n",
      "predictor: 2+abs_freq Lambda: 1.476960\n",
      "predictor: 3+abs_freq Lambda: 1.303700\n",
      "predictor: 5+abs_freq Lambda: 1.360663\n",
      "predictor: 6+abs_freq Lambda: 2.129595\n",
      "predictor: 7+abs_freq Lambda: 1.625136\n",
      "predictor: 9+abs_freq Lambda: 1.370512\n",
      "predictor: 10+abs_freq Lambda: 1.530380\n",
      "predictor: 15+abs_freq Lambda: 1.418165\n",
      "predictor: 17+abs_freq Lambda: 1.339855\n",
      "predictor: 18+abs_freq Lambda: 1.287568\n",
      "predictor: 21+abs_freq Lambda: 1.405187\n",
      "predictor: 22+abs_freq Lambda: 1.314721\n",
      "predictor: 23+abs_freq Lambda: 0.967400\n",
      "predictor: 24+abs_freq Lambda: 1.298801\n",
      "predictor: 26+abs_freq Lambda: 1.338248\n",
      "predictor: 27+abs_freq Lambda: 1.682467\n",
      "predictor: 29+abs_freq Lambda: 1.392451\n",
      "predictor: 30+abs_freq Lambda: 1.280578\n",
      "predictor: 31+abs_freq Lambda: 1.222675\n",
      "predictor: 32+abs_freq Lambda: 1.286915\n",
      "predictor: 36+abs_freq Lambda: 1.282765\n",
      "predictor: 44+abs_freq Lambda: 1.660219\n",
      "predictor: 45+abs_freq Lambda: 1.420735\n",
      "predictor: 47+abs_freq Lambda: 1.972705\n",
      "predictor: 48+abs_freq Lambda: 1.322145\n",
      "predictor: 50+abs_freq Lambda: 1.375670\n",
      "predictor: 51+abs_freq Lambda: 1.584609\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be positive.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-29378291151e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Однако остальные преобразования были выполнены.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predictor:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Lambda: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlam\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36mboxcox\u001b[1;34m(x, lmbda, alpha)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be positive.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlmbda\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# single transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be positive."
     ]
    }
   ],
   "source": [
    "# импортируем функцию boxcox\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# выполняем преобразование Бокса-Кокса. P.S. когда скрипт дошел до дамми-переменных, появилась ошибка.\n",
    "# Однако остальные преобразования были выполнены.\n",
    "for i in train_dummy.columns:\n",
    "    transformed, lam = boxcox(np.absolute(train_dummy[i]))\n",
    "    print('predictor:', i, 'Lambda: %f' % lam)\n",
    "    if lam < -0.25:\n",
    "        train_dummy[i] = np.sign(train_dummy[i]) * (np.absolute(train_dummy[i])** (-1/2))\n",
    "        test_dummy[i] = np.sign(test_dummy[i]) * (np.absolute(test_dummy[i])** (-1/2))\n",
    "        X_test_dummy[i] = np.sign(X_test_dummy[i]) * (np.absolute(X_test_dummy[i])** (-1/2))\n",
    "    if -0.25 <= lam <= 0.25:\n",
    "        train_dummy[i] = np.log(np.absolute(train_dummy[i])+ 0.001)\n",
    "        test_dummy[i] = np.log(np.absolute(test_dummy[i])+ 0.001)\n",
    "        X_test_dummy[i] = np.log(np.absolute(X_test_dummy[i])+ 0.001)\n",
    "    if 0.25 < lam < 0.75:\n",
    "        train_dummy[i] = np.sign(train_dummy[i]) * (np.absolute(train_dummy[i])** (1/2))\n",
    "        test_dummy[i] = np.sign(test_dummy[i]) * (np.absolute(test_dummy[i])** (1/2))\n",
    "        X_test_dummy[i] = np.sign(X_test_dummy[i]) * (np.absolute(X_test_dummy[i])** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выполним стандартизацию\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Подгоняем нашу модель\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_dummy) \n",
    "\n",
    "\n",
    "scaler_1 = StandardScaler()\n",
    "scaler_1.fit(train_importance) \n",
    "\n",
    "# Преобразовываем данные\n",
    "train_scaled = scaler.transform(train_dummy)\n",
    "test_scaled = scaler.transform(test_dummy)\n",
    "X_test_scaled = scaler.transform(X_test_dummy)\n",
    "\n",
    "train_scaled_1 = scaler_1.transform(train_importance)\n",
    "test_scaled_1 = scaler_1.transform(test_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на обучающей выборке: 0.693\n",
      "Правильность на контрольной выборке: 0.693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 500, max_depth = 10, max_features = 50, min_samples_split = 2, min_samples_leaf = 1, random_state=152)\n",
    "forest.fit(train_scaled, y_train)\n",
    "print('Правильность на обучающей выборке: {:.3f}'.format(forest.score(train_scaled, y_train)))\n",
    "print('Правильность на контрольной выборке: {:.3f}'.format(forest.score(test_scaled, y_test)))                                                                                         ю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) 34                                  0.210391\n",
      " 2) 34square                            0.202482\n",
      " 3) 37                                  0.042623\n",
      " 4) 37square                            0.041626\n",
      " 5) 10_1.0                              0.021915\n",
      " 6) 42                                  0.019269\n",
      " 7) 42square                            0.018257\n",
      " 8) 10+freq                             0.013277\n",
      " 9) 12square                            0.012894\n",
      "10) 10+abs_freq                         0.011663\n",
      "11) 10_0.0                              0.010873\n",
      "12) 12                                  0.010271\n",
      "13) 38square                            0.007416\n",
      "14) 38                                  0.006677\n",
      "15) 19                                  0.006342\n",
      "16) 25square                            0.006132\n",
      "17) 11                                  0.005797\n",
      "18) 1square                             0.005684\n",
      "19) 46square                            0.005630\n",
      "20) 11square                            0.005612\n",
      "21) 41                                  0.005544\n",
      "22) 46                                  0.005536\n",
      "23) 19square                            0.005464\n",
      "24) 53square                            0.005419\n",
      "25) 41square                            0.005412\n",
      "26) 40                                  0.005370\n",
      "27) 16square                            0.005352\n",
      "28) 14square                            0.005325\n",
      "29) 4square                             0.005318\n",
      "30) 55                                  0.005308\n",
      "31) 52square                            0.005300\n",
      "32) 33square                            0.005260\n",
      "33) 40square                            0.005243\n",
      "34) 20square                            0.005241\n",
      "35) 20                                  0.005224\n",
      "36) 14                                  0.005222\n",
      "37) 58                                  0.005181\n",
      "38) 4                                   0.005176\n",
      "39) 39square                            0.005171\n",
      "40) 25                                  0.005162\n",
      "41) 1                                   0.005127\n",
      "42) 8square                             0.005118\n",
      "43) 16                                  0.005113\n",
      "44) 53                                  0.005085\n",
      "45) 56square                            0.005079\n",
      "46) 54                                  0.005056\n",
      "47) 52                                  0.005046\n",
      "48) 57                                  0.005038\n",
      "49) 57square                            0.005032\n",
      "50) 58square                            0.005026\n",
      "51) 39                                  0.004963\n",
      "52) 56                                  0.004927\n",
      "53) 8                                   0.004902\n",
      "54) 35                                  0.004895\n",
      "55) 13square                            0.004892\n",
      "56) 13                                  0.004884\n",
      "57) 55square                            0.004872\n",
      "58) 54square                            0.004829\n",
      "59) 28square                            0.004809\n",
      "60) 28                                  0.004805\n",
      "61) 33                                  0.004804\n",
      "62) 49                                  0.004797\n",
      "63) 43square                            0.004789\n",
      "64) 35square                            0.004713\n",
      "65) 49square                            0.004674\n",
      "66) 43                                  0.004638\n",
      "67) 10_nan                              0.001968\n",
      "68) 51+freq                             0.001725\n",
      "69) 27+freq                             0.001709\n",
      "70) 27+abs_freq                         0.001629\n",
      "71) 26+freq                             0.001627\n",
      "72) 26+abs_freq                         0.001598\n",
      "73) 51+abs_freq                         0.001574\n",
      "74) 21+abs_freq                         0.001527\n",
      "75) 17+abs_freq                         0.001443\n",
      "76) 3+abs_freq                          0.001420\n",
      "77) 48+abs_freq                         0.001420\n",
      "78) 36+freq                             0.001416\n",
      "79) 24+freq                             0.001414\n",
      "80) 3+freq                              0.001379\n",
      "81) 48+freq                             0.001366\n",
      "82) 17+freq                             0.001352\n",
      "83) 29+abs_freq                         0.001346\n",
      "84) 24+abs_freq                         0.001342\n",
      "85) 36+abs_freq                         0.001311\n",
      "86) 21+freq                             0.001265\n",
      "87) 18+freq                             0.001257\n",
      "88) 15+freq                             0.001255\n",
      "89) 32+abs_freq                         0.001242\n",
      "90) 22+abs_freq                         0.001232\n",
      "91) 32+freq                             0.001230\n",
      "92) 15+abs_freq                         0.001212\n",
      "93) 22+freq                             0.001210\n",
      "94) 18+abs_freq                         0.001191\n",
      "95) 29+freq                             0.001182\n",
      "96) 50+abs_freq                         0.001063\n",
      "97) 50+freq                             0.001045\n",
      "98) 9+freq                              0.001026\n",
      "99) 31+freq                             0.000949\n",
      "100) 31+abs_freq                         0.000921\n",
      "101) 9+abs_freq                          0.000880\n",
      "102) 44+freq                             0.000865\n",
      "103) 45+abs_freq                         0.000850\n",
      "104) 44+abs_freq                         0.000840\n",
      "105) 45+freq                             0.000823\n",
      "106) 7+abs_freq                          0.000787\n",
      "107) 23+freq                             0.000771\n",
      "108) 23+abs_freq                         0.000756\n",
      "109) 7+freq                              0.000755\n",
      "110) 6+freq                              0.000747\n",
      "111) 6+abs_freq                          0.000737\n",
      "112) 30+freq                             0.000732\n",
      "113) 2+abs_freq                          0.000692\n",
      "114) 2+freq                              0.000673\n",
      "115) 30+abs_freq                         0.000624\n",
      "116) 5+freq                              0.000557\n",
      "117) 5+abs_freq                          0.000489\n",
      "118) 47+abs_freq                         0.000395\n",
      "119) 36_4.0                              0.000351\n",
      "120) 31_3.0                              0.000350\n",
      "121) 47+freq                             0.000344\n",
      "122) 7_23.0                              0.000310\n",
      "123) 18_3.0                              0.000304\n",
      "124) 32_5.0                              0.000301\n",
      "125) 9_7.0                               0.000299\n",
      "126) 44_0.0                              0.000298\n",
      "127) 29_nan                              0.000297\n",
      "128) 15_18.0                             0.000295\n",
      "129) 44_2.0                              0.000295\n",
      "130) 30_0.0                              0.000289\n",
      "131) 50_4.0                              0.000289\n",
      "132) 6_1.0                               0.000285\n",
      "133) 18_2.0                              0.000284\n",
      "134) 32_3.0                              0.000282\n",
      "135) 31_5.0                              0.000281\n",
      "136) 21_nan                              0.000280\n",
      "137) 23_3.0                              0.000278\n",
      "138) 9_8.0                               0.000277\n",
      "139) 45_10.0                             0.000276\n",
      "140) 22_5.0                              0.000276\n",
      "141) 47_0.0                              0.000276\n",
      "142) 15_16.0                             0.000275\n",
      "143) 24_6.0                              0.000275\n",
      "144) 32_2.0                              0.000275\n",
      "145) 27_12.0                             0.000273\n",
      "146) 23_1.0                              0.000272\n",
      "147) 2_12.0                              0.000272\n",
      "148) 5_1.0                               0.000271\n",
      "149) 51_14.0                             0.000269\n",
      "150) 45_12.0                             0.000266\n",
      "151) 22_3.0                              0.000264\n",
      "152) 26_16.0                             0.000264\n",
      "153) 24_7.0                              0.000262\n",
      "154) 21_3.0                              0.000262\n",
      "155) 17_16.0                             0.000261\n",
      "156) 2_11.0                              0.000261\n",
      "157) 6_2.0                               0.000256\n",
      "158) 29_2.0                              0.000256\n",
      "159) 51_nan                              0.000255\n",
      "160) 50_5.0                              0.000255\n",
      "161) 27_14.0                             0.000254\n",
      "162) 17_17.0                             0.000250\n",
      "163) 50_3.0                              0.000250\n",
      "164) 36_5.0                              0.000249\n",
      "165) 3_11.0                              0.000249\n",
      "166) 47_1.0                              0.000248\n",
      "167) 50_1.0                              0.000247\n",
      "168) 26_13.0                             0.000247\n",
      "169) 3_13.0                              0.000244\n",
      "170) 51_16.0                             0.000244\n",
      "171) 7_nan                               0.000244\n",
      "172) 48_7.0                              0.000242\n",
      "173) 29_3.0                              0.000241\n",
      "174) 23_nan                              0.000241\n",
      "175) 3_14.0                              0.000240\n",
      "176) 22_nan                              0.000240\n",
      "177) 17_15.0                             0.000239\n",
      "178) 26_14.0                             0.000237\n",
      "179) 31_4.0                              0.000237\n",
      "180) 27_15.0                             0.000236\n",
      "181) 50_2.0                              0.000236\n",
      "182) 51_13.0                             0.000235\n",
      "183) 51_15.0                             0.000235\n",
      "184) 27_11.0                             0.000235\n",
      "185) 3_12.0                              0.000234\n",
      "186) 15_17.0                             0.000233\n",
      "187) 21_4.0                              0.000233\n",
      "188) 48_6.0                              0.000232\n",
      "189) 15_19.0                             0.000231\n",
      "190) 3_10.0                              0.000230\n",
      "191) 6_3.0                               0.000229\n",
      "192) 45_11.0                             0.000228\n",
      "193) 27_10.0                             0.000227\n",
      "194) 26_15.0                             0.000226\n",
      "195) 26_12.0                             0.000225\n",
      "196) 36_nan                              0.000223\n",
      "197) 18_4.0                              0.000223\n",
      "198) 48_3.0                              0.000223\n",
      "199) 24_1.0                              0.000221\n",
      "200) 22_4.0                              0.000221\n",
      "201) 6_nan                               0.000221\n",
      "202) 47_nan                              0.000220\n",
      "203) 27_16.0                             0.000220\n",
      "204) 7_24.0                              0.000218\n",
      "205) 29_4.0                              0.000218\n",
      "206) 9_6.0                               0.000217\n",
      "207) 5_0.0                               0.000217\n",
      "208) 31_2.0                              0.000217\n",
      "209) 18_nan                              0.000217\n",
      "210) 2_nan                               0.000216\n",
      "211) 9_nan                               0.000214\n",
      "212) 23_2.0                              0.000214\n",
      "213) 36_2.0                              0.000212\n",
      "214) 48_nan                              0.000212\n",
      "215) 17_nan                              0.000212\n",
      "216) 21_6.0                              0.000211\n",
      "217) 44_1.0                              0.000211\n",
      "218) 22_6.0                              0.000210\n",
      "219) 24_3.0                              0.000210\n",
      "220) 30_nan                              0.000208\n",
      "221) 24_4.0                              0.000208\n",
      "222) 36_3.0                              0.000208\n",
      "223) 17_18.0                             0.000208\n",
      "224) 29_6.0                              0.000207\n",
      "225) 18_1.0                              0.000207\n",
      "226) 48_2.0                              0.000206\n",
      "227) 15_nan                              0.000206\n",
      "228) 51_12.0                             0.000204\n",
      "229) 29_1.0                              0.000204\n",
      "230) 21_2.0                              0.000203\n",
      "231) 9_10.0                              0.000203\n",
      "232) 44_nan                              0.000201\n",
      "233) 22_2.0                              0.000201\n",
      "234) 51_17.0                             0.000200\n",
      "235) 31_nan                              0.000200\n",
      "236) 27_nan                              0.000199\n",
      "237) 21_7.0                              0.000198\n",
      "238) 21_1.0                              0.000198\n",
      "239) 51_18.0                             0.000198\n",
      "240) 15_15.0                             0.000198\n",
      "241) 18_5.0                              0.000197\n",
      "242) 32_4.0                              0.000196\n",
      "243) 26_nan                              0.000196\n",
      "244) 7_22.0                              0.000194\n",
      "245) 44_3.0                              0.000194\n",
      "246) 24_nan                              0.000192\n",
      "247) 29_5.0                              0.000191\n",
      "248) 26_10.0                             0.000190\n",
      "249) 32_nan                              0.000190\n",
      "250) 3_nan                               0.000189\n",
      "251) 24_2.0                              0.000189\n",
      "252) 17_14.0                             0.000188\n",
      "253) 30_1.0                              0.000188\n",
      "254) 24_8.0                              0.000188\n",
      "255) 36_1.0                              0.000187\n",
      "256) 9_9.0                               0.000187\n",
      "257) 27_9.0                              0.000182\n",
      "258) 5_nan                               0.000181\n",
      "259) 48_1.0                              0.000176\n",
      "260) 36_6.0                              0.000176\n",
      "261) 51_19.0                             0.000175\n",
      "262) 3_8.0                               0.000175\n",
      "263) 15_14.0                             0.000173\n",
      "264) 21_5.0                              0.000173\n",
      "265) 50_nan                              0.000172\n",
      "266) 48_5.0                              0.000172\n",
      "267) 2_13.0                              0.000172\n",
      "268) 48_4.0                              0.000172\n",
      "269) 32_1.0                              0.000171\n",
      "270) 51_11.0                             0.000171\n",
      "271) 27_13.0                             0.000170\n",
      "272) 18_6.0                              0.000169\n",
      "273) 26_11.0                             0.000169\n",
      "274) 32_6.0                              0.000168\n",
      "275) 45_nan                              0.000168\n",
      "276) 24_5.0                              0.000166\n",
      "277) 30_2.0                              0.000157\n",
      "278) 17_19.0                             0.000156\n",
      "279) 24_9.0                              0.000156\n",
      "280) 26_17.0                             0.000154\n",
      "281) 3_9.0                               0.000154\n",
      "282) 45_9.0                              0.000152\n",
      "283) 36_7.0                              0.000150\n",
      "284) 15_20.0                             0.000149\n",
      "285) 50_0.0                              0.000144\n",
      "286) 22_1.0                              0.000143\n",
      "287) 23_0.0                              0.000143\n",
      "288) 22_7.0                              0.000142\n",
      "289) 27_17.0                             0.000141\n",
      "290) 7_21.0                              0.000137\n",
      "291) 51_10.0                             0.000137\n",
      "292) 3_15.0                              0.000132\n",
      "293) 6_0.0                               0.000127\n",
      "294) 27_8.0                              0.000125\n",
      "295) 26_18.0                             0.000124\n",
      "296) 17_20.0                             0.000123\n",
      "297) 2_10.0                              0.000122\n",
      "298) 21_8.0                              0.000121\n",
      "299) 29_0.0                              0.000119\n",
      "300) 9_5.0                               0.000118\n",
      "301) 27_18.0                             0.000117\n",
      "302) 21_9.0                              0.000115\n",
      "303) 17_13.0                             0.000111\n",
      "304) 29_7.0                              0.000110\n",
      "305) 21_0.0                              0.000110\n",
      "306) 22_8.0                              0.000110\n",
      "307) 5_2.0                               0.000107\n",
      "308) 17_12.0                             0.000107\n",
      "309) 36_0.0                              0.000106\n",
      "310) 32_7.0                              0.000104\n",
      "311) 18_0.0                              0.000100\n",
      "312) 26_9.0                              0.000096\n",
      "313) 15_13.0                             0.000096\n",
      "314) 18_7.0                              0.000096\n",
      "315) 48_8.0                              0.000094\n",
      "316) 27_19.0                             0.000093\n",
      "317) 36_8.0                              0.000089\n",
      "318) 51_20.0                             0.000083\n",
      "319) 31_1.0                              0.000082\n",
      "320) 24_10.0                             0.000082\n",
      "321) 3_7.0                               0.000080\n",
      "322) 48_0.0                              0.000079\n",
      "323) 51_9.0                              0.000064\n",
      "324) 32_0.0                              0.000063\n",
      "325) 22_9.0                              0.000063\n",
      "326) 32_8.0                              0.000058\n",
      "327) 45_8.0                              0.000057\n",
      "328) 26_8.0                              0.000055\n",
      "329) 27_7.0                              0.000051\n",
      "330) 30_3.0                              0.000047\n",
      "331) 48_9.0                              0.000042\n",
      "332) 26_19.0                             0.000038\n"
     ]
    }
   ],
   "source": [
    "feat_labels = train_dummy.columns\n",
    "importances =  forest.feature_importances_\n",
    "# сортирум важности по убыванию\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# сопоставляем важности названиям предикторов\n",
    "for f in range(train_dummy.shape[1]):\n",
    "    print('%2d) %-*s %f' % (f + 1, 35,\n",
    "                            feat_labels[indices[f]],\n",
    "                            importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dummy.shape[1]\n",
    "m = list(feat_labels[indices[0:25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим логистическую регрессию.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Обучаем нашу модель\n",
    "logreg = LogisticRegression().fit(train_scaled, y_train)\n",
    "\n",
    "# Вычисляем ROC_AUC на обучающей и тестовой выборке для модели логистической регрессии\n",
    "print(\"AUC на обучающей выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_train, logreg.predict_proba(train_scaled)[:, 1])))\n",
    "print(\"AUC на контрольной выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_test, logreg.predict_proba(test_scaled)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "logreg_grid = LogisticRegression(penalty='l1')\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.3, 0.6]} # Задаем решетку параметров\n",
    "\n",
    "stratcv = StratifiedKFold(n_splits=10) # Указываем количество блоков для кросс-валидации\n",
    "\n",
    "# создаем экземпляр класса GridSearchCV\n",
    "grid_search = GridSearchCV(logreg_grid, param_grid, \n",
    "                           scoring='roc_auc', \n",
    "                           n_jobs=-1, cv=stratcv)\n",
    "# запускаем решетчатый поиск\n",
    "grid_search.fit(train_scaled, y_train)\n",
    "\n",
    "test_score = roc_auc_score(y_train, grid_search.predict_proba(train_scaled)[:, 1])\n",
    "# смотрим результаты GridSearchCV\n",
    "print('AUC на тестовой выборке: {:.3f}'.format(test_score))\n",
    "print('Наилучшее значение гиперпараметра C: {}'.format(grid_search.best_params_))\n",
    "print('Наилучшее значение AUC: {:.3f}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.04, max_depth=10, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.8,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем обучить более сложную модель\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier(boosting_type='gbdt', max_depth=10, learning_rate=0.04, n_estimators=1000, subsample=0.8)\n",
    "clf.fit(train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC на обучающей выборке: 0.785\n",
      "AUC на контрольной выборке: 0.736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC на обучающей выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_train, clf.predict_proba(train_scaled)[:, 1])))\n",
    "print(\"AUC на контрольной выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_test, clf.predict_proba(test_scaled)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "strat_split = StratifiedKFold(n_splits=3, shuffle=True, random_state=777)\n",
    "\n",
    "clf_lightGBM = lgb.LGBMClassifier(max_depth=6, random_state=777)\n",
    "param_grid = {'n_estimators': [100, 300, 500, 1000],\n",
    "             'learning_rate':[0.01, 0.05, 0.1, 0.3]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_lightGBM, param_grid, scoring='roc_auc', n_jobs=-1, cv=strat_split)\n",
    "grid_search.fit(train_scaled, y_train)\n",
    "test_score = roc_auc_score(y_test, grid_search.predict_proba(test_scaled)[:, 1])\n",
    "print(\"Наилучшее значение AUC:\", grid_search.best_score_)\n",
    "print(\"Наилучшие значения параметров:\", grid_search.best_params_)\n",
    "print(\"AUC на тестовой выборке:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC на обучающей выборке: 0.959\n",
      "AUC на контрольной выборке: 0.785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC на обучающей выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_train, Boost.predict_proba(train_scaled_1)[:, 1])))\n",
    "print(\"AUC на контрольной выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_test, Boost.predict_proba(test_scaled_1)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC на обучающей выборке: 0.986\n",
      "AUC на контрольной выборке: 0.779\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC на обучающей выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_train, Boost.predict_proba(train_scaled)[:, 1])))\n",
    "print(\"AUC на контрольной выборке: {:.3f}\".\n",
    "      format(roc_auc_score(y_test, Boost.predict_proba(test_scaled)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "strat_split = StratifiedKFold(n_splits=3, shuffle=True, random_state=777)\n",
    "\n",
    "clf_XGBoost_strat = XGB.XGBClassifier(max_depth=6, random_state=777)\n",
    "param_grid = {'n_estimators': [100, 300, 1200],\n",
    "             'learning_rate':[0.01, 0.05, 0.1]}\n",
    "\n",
    "grid_search = GridSearchCV(clf_XGBoost_strat, param_grid, scoring='roc_auc', n_jobs=-1, cv=strat_split)\n",
    "grid_search.fit(train_scaled, y_train)\n",
    "test_score = roc_auc_score(y_test, grid_search.predict_proba(test_scaled)[:, 1])\n",
    "print(\"Наилучшее значение AUC:\", grid_search.best_score_)\n",
    "print(\"Наилучшие значения параметров:\", grid_search.best_params_)\n",
    "print(\"AUC на тестовой выборке:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
